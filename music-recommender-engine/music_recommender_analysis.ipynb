{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f616d8",
   "metadata": {},
   "source": [
    "# Project Goal\n",
    "The goal of this project is to build a simple content-based music recommendation engine. The system will recommend songs to a user based on the lyrical similarity of a song they choose.\n",
    "\n",
    "### 1. Data Loading\n",
    "\n",
    "I am using a pre-processed version of the Spotify Million Song Dataset. With a file size of only 75 MB, the dataset is small enough to be loaded directly into a single Pandas DataFrame. This allows for more straightforward data manipulation and analysis, as opposed to processing in chunks.\n",
    "\n",
    "The dataset contains the following key columns:\n",
    "\n",
    "Artist: The artist's name.\n",
    "\n",
    "Song: The song's title.\n",
    "\n",
    "Link: A link to the song's lyrics page.\n",
    "\n",
    "Text: The lyrics of the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891f0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your dataset file.\n",
    "file_path = r'.\\spotify_millsongdata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af5fdc",
   "metadata": {},
   "source": [
    "#### Skipped processing in chunks as dataset is small\n",
    "\n",
    "My initial plan was to process this data in chunks to handle a potentially large file. However, after inspection, the dataset size was found to be much smaller than anticipated (~75MB), making chunked processing unnecessary.\n",
    "\n",
    "The following code was originally planned but skipped:\n",
    "\n",
    "##### # Set the chunk size (e.g., 10,000 rows at a time).\n",
    "chunk_size = 10000\n",
    "\n",
    "##### # Create a generator that reads the file in chunks.\n",
    "chunks = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "\n",
    "##### # You can iterate through the chunks to inspect the data.\n",
    "##### # For now, let's just look at the first chunk to see the column names.\n",
    "first_chunk = next(chunks)\n",
    "print(first_chunk.info())\n",
    "print(first_chunk.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d99251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57650 entries, 0 to 57649\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   artist  57650 non-null  object\n",
      " 1   song    57650 non-null  object\n",
      " 2   link    57650 non-null  object\n",
      " 3   text    57650 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the entire dataset into a single DataFrame.\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(df.info())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d36527",
   "metadata": {},
   "source": [
    "### 6.1. Data Sampling: The Solution to MemoryError (Skip this step for now and follow order of numbering)\n",
    "\n",
    "Initial attempts to compute the song similarity matrix resulted in a MemoryError, as the resulting dense matrix was too large to fit into RAM. To solve this, I used data sampling, a common professional strategy for working with large datasets.\n",
    "\n",
    "I took a random sample of 5,000 songs from the original dataset. This approach allows me to build a fully functional and representative proof-of-concept without sacrificing the core methodology, which is a key skill for data professionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740fcf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the sampled DataFrame: (5000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Sample the DataFrame to a smaller size (e.g., 5000 songs)\n",
    "df = df.sample(n=5000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print the new shape of the DataFrame\n",
    "print(\"Shape of the sampled DataFrame:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c97502",
   "metadata": {},
   "source": [
    "### 2. Initial Data Exploration\n",
    "After loading the dataset, I'll perform an initial check to understand its structure, identify any missing values, and verify the data types of each column. This is a critical step to ensure the data is clean and ready for analysis.\n",
    "\n",
    "I'll use the following Pandas methods for this exploration:\n",
    "\n",
    "df.info(): Provides a summary of the DataFrame, including the column names, number of non-null values, and data types.\n",
    "\n",
    "df.head(): Displays the first few rows of the DataFrame, giving a quick look at the data.\n",
    "\n",
    "df.isnull().sum(): Counts the number of missing values in each column, which is essential for data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa53ffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   artist  5000 non-null   object\n",
      " 1   song    5000 non-null   object\n",
      " 2   link    5000 non-null   object\n",
      " 3   text    5000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dced231b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "artist",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "song",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "699e26e8-10ea-4d48-9812-1841675bd247",
       "rows": [
        [
         "0",
         "Wishbone Ash",
         "Right Or Wrong",
         "/w/wishbone+ash/right+or+wrong_20147150.html",
         "Like to have you 'round  \r\nWith all the lies that you make  \r\nThe things or darkness and you  \r\nSome people say, have just a taste  \r\nRight or wrong, you might get burned  \r\nWhat you gain is what you learn  \r\n  \r\nGot one too many women  \r\nDon't know quite which way to go  \r\nThey're all gettin' so expensive  \r\nWhen they walk by themselves  \r\nRight or wrong, don't regret  \r\nWhat you went for is what you get  \r\n  \r\nNo point in bitter tears  \r\nWhen someone else has cut you down  \r\n'Cause there's a time for leavin'  \r\nAnd there's a time for stickin' around, hey  \r\nRight or wrong, you've got to live  \r\nSo what you collect is what you give\r\n\r\n"
        ],
        [
         "1",
         "Aerosmith",
         "This Little Light Of Mine",
         "/a/aerosmith/this+little+light+of+mine_20644484.html",
         "This Little Light of Mine (Light of Mine),  \r\nI'm Let it shine (Aleilujah),  \r\nThis Little Light of Mine, I'm gonna let it shine,  \r\n  \r\nDown in my heart (In my heart),  \r\nI'm gonna let it shine (Aleilujah)  \r\nDown in my heart (In My heart)  \r\nI'm gonna let it, let it shine.  \r\n  \r\nAll over the world (All over the world),  \r\nI'm gonna let it shine (Let it shine, let it shine let it shine)  \r\nLet it shine, let it shine, let it shine, let it shine\r\n\r\n"
        ],
        [
         "2",
         "Fall Out Boy",
         "Dance, Dance",
         "/f/fall+out+boy/dance+dance_10113666.html",
         "She says she's no good with words but I'm worse  \r\nBarely stuttered out  \r\nA joke of a romantic stuck to my tongue  \r\nAnd weighed down with words too overdramatic  \r\nTonight it's \"it can't get much worse\"  \r\nVs. \"no one should ever feel like..\"  \r\n  \r\nI'm two quarters and a heart down  \r\nAnd I don't want to forget how your voice sounds  \r\nThese words are all I have so I write them  \r\nI need them just to get by  \r\n  \r\nDance, dance  \r\nWe're falling apart to half time  \r\nDance, dance  \r\nAnd these are the lives you love to lead  \r\nDance this is the way they'd look  \r\nIf they knew how misery loved me  \r\n  \r\n  \r\nYou always fold just before you're found out  \r\nDrink up its last call  \r\nLast resort  \r\nBut only the first mistake and I  \r\n  \r\nI'm two quarters and a heart down  \r\nAnd I don't want to forget how your voice sounds  \r\nThese words are all I have so I write them  \r\nI need them just to get by  \r\n  \r\nWhy don't you show me a little bit of spine  \r\nYou've been saving for his mattress (love)  \r\n  \r\nDance, dance  \r\nWe're falling apart to half time  \r\nDance, dance  \r\nAnd these are the lives you love to lead  \r\nDance this is the way they'd look  \r\nIf they knew how misery loved me  \r\n  \r\nWhy don't you show me a little bit of spine  \r\nYou've been saving for his mattress (with love)  \r\nI only want sympathy in the form of you crawling into bed with me  \r\n  \r\nDance, dance, we're falling apart to half time  \r\nDance, dance, and these are the lives you love to lead  \r\nDance this is the way they'd look  \r\nIf they knew how misery loved me\r\n\r\n"
        ],
        [
         "3",
         "Janis Joplin",
         "Easy Rider",
         "/j/janis+joplin/easy+rider_10147381.html",
         "Hey mama, mama, come a look at sister,  \r\nShe's a-standing on the levee trying to do that twist,  \r\nBut easy rider don't you deny my name,  \r\nOh no, oh no.  \r\nWell, I got a girl with a diamond ring,  \r\nI'll tell you, boys, she knows how to shake that thing.  \r\nOh! Easy rider don't you deny my name,  \r\nOh no, oh no.  \r\nPlay it!  \r\nWell, I got a horse and he lives in a tree,  \r\nHe watches Huckleberry Hound on his tv.  \r\nBut easy rider don't you deny my name,  \r\nOh no, oh no.  \r\nI would buy you a plastic suit  \r\nAnd I would even buy you some cardboard fruit.  \r\nOh! But easy rider don't you deny my name,  \r\nOh no, oh no.  \r\nYeah, easy rider, don't you deny my name, pretty baby doll  \r\nI said, easy rider, don't you deny my name, pretty baby doll  \r\nI said, easy rider, don't you deny my name, pretty baby doll  \r\nI said, easy rider, don't you deny my name, pretty baby...\r\n\r\n"
        ],
        [
         "4",
         "Moody Blues",
         "Peak Hour",
         "/m/moody+blues/peak+hour_20291295.html",
         "I see it all through my window it seems.  \r\nNever failing, like millions of eels.  \r\nAll that is wrong,  \r\nNo time to be won.  \r\nOnly to do  \r\nWhat can be done.  \r\nPeak hour,  \r\nPeak hour,  \r\nPeak hour.  \r\nMinds are subject to what should be done.  \r\nProblem solved, time cannot be won.  \r\nOne hour a day,  \r\nOne hour a night  \r\nSees crowds of people  \r\nHome-aimed for flight.  \r\nPeak hour,  \r\nPeak hour,  \r\nPeak hour.  \r\nIt makes me want to run out and tell them  \r\nThey've got time.  \r\nTake a step back out and warn them  \r\nI've found out I've got time.  \r\nMinds are subject to what should be done.  \r\nProblem solved, time cannot be won.  \r\nOne hour a day,  \r\nOne hour a night  \r\nSees crowds of people  \r\nHome-aimed for flight.  \r\nPeak hour,  \r\nPeak hour,  \r\nPeak hour.\r\n\r\n"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wishbone Ash</td>\n",
       "      <td>Right Or Wrong</td>\n",
       "      <td>/w/wishbone+ash/right+or+wrong_20147150.html</td>\n",
       "      <td>Like to have you 'round  \\r\\nWith all the lies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aerosmith</td>\n",
       "      <td>This Little Light Of Mine</td>\n",
       "      <td>/a/aerosmith/this+little+light+of+mine_2064448...</td>\n",
       "      <td>This Little Light of Mine (Light of Mine),  \\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fall Out Boy</td>\n",
       "      <td>Dance, Dance</td>\n",
       "      <td>/f/fall+out+boy/dance+dance_10113666.html</td>\n",
       "      <td>She says she's no good with words but I'm wors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Janis Joplin</td>\n",
       "      <td>Easy Rider</td>\n",
       "      <td>/j/janis+joplin/easy+rider_10147381.html</td>\n",
       "      <td>Hey mama, mama, come a look at sister,  \\r\\nSh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moody Blues</td>\n",
       "      <td>Peak Hour</td>\n",
       "      <td>/m/moody+blues/peak+hour_20291295.html</td>\n",
       "      <td>I see it all through my window it seems.  \\r\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist                       song  \\\n",
       "0  Wishbone Ash             Right Or Wrong   \n",
       "1     Aerosmith  This Little Light Of Mine   \n",
       "2  Fall Out Boy               Dance, Dance   \n",
       "3  Janis Joplin                 Easy Rider   \n",
       "4   Moody Blues                  Peak Hour   \n",
       "\n",
       "                                                link  \\\n",
       "0       /w/wishbone+ash/right+or+wrong_20147150.html   \n",
       "1  /a/aerosmith/this+little+light+of+mine_2064448...   \n",
       "2          /f/fall+out+boy/dance+dance_10113666.html   \n",
       "3           /j/janis+joplin/easy+rider_10147381.html   \n",
       "4             /m/moody+blues/peak+hour_20291295.html   \n",
       "\n",
       "                                                text  \n",
       "0  Like to have you 'round  \\r\\nWith all the lies...  \n",
       "1  This Little Light of Mine (Light of Mine),  \\r...  \n",
       "2  She says she's no good with words but I'm wors...  \n",
       "3  Hey mama, mama, come a look at sister,  \\r\\nSh...  \n",
       "4  I see it all through my window it seems.  \\r\\n...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ab50b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f73e0f86-94bd-40a6-b8af-59360771d15c",
       "rows": [
        [
         "artist",
         "0"
        ],
        [
         "song",
         "0"
        ],
        [
         "link",
         "0"
        ],
        [
         "text",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "artist    0\n",
       "song      0\n",
       "link      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b797e92",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning: No Missing Values\n",
    "\n",
    "After loading the dataset, I performed an initial check for missing values using `df.isnull().sum()`. The results show that there are no missing values in any of the columns. This means the dataset is already clean and ready for analysis, and no further cleaning is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34ccbb",
   "metadata": {},
   "source": [
    "### 4. Text Preprocessing: Getting the Lyrics Ready for Analysis\n",
    "\n",
    "To prepare the lyrical data for the recommendation engine, I created a preprocessing function to transform the raw text into a clean and consistent format. This is a crucial step in Natural Language Processing (NLP).\n",
    "\n",
    "The `preprocess_text` function performs the following steps:\n",
    "- **Lowercase Conversion**: All text is converted to lowercase to ensure consistency (`'The'` and `'the'` are treated as the same word).\n",
    "- **Punctuation Removal**: str.maketrans and string.punctuation from string module are used to remove punctuation and special characters that don't contribute to the meaning of the lyrics.\n",
    "- **Tokenization**: The cleaned text is split into individual words.\n",
    "- **Stop Word Removal**: Common, non-meaningful words (e.g., `'a'`, `'the'`, `'is'`) are filtered out using `nltk`'s built-in stop words list.\n",
    "- **Stemming**: I used the `PorterStemmer` to reduce words to their root form (e.g., `'running'` and `'runs'` become `'run'`). This helps improve the accuracy of the similarity calculation.\n",
    "\n",
    "I applied this function to the `text` column of the DataFrame to create a new `processed_text` column, which now contains the cleaned and ready-to-use lyrical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98060b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31af9438-646b-4c1c-aece-f11668018920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses a string of text for natural language processing (NLP).\n",
    "\n",
    "    The function performs a series of operations to prepare the text:\n",
    "    1. Converts text to lowercase.\n",
    "    2. Removes all punctuation.\n",
    "    3. Tokenizes the text into a list of words.\n",
    "    4. Removes common English stop words.\n",
    "    5. Applies stemming to reduce words to their root form.\n",
    "\n",
    "    Args:\n",
    "        text (str): The raw text string to be processed.\n",
    "\n",
    "    Returns:\n",
    "        str: The processed text as a single string of stemmed words.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "\n",
    "    # Create a translation table to delete all punctuation characters\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    # Apply the translation table to the text\n",
    "    text_without_punctuation = text.translate(translator)\n",
    "\n",
    "    # Initialize stop words and stemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text_without_punctuation)\n",
    "    \n",
    "    # Process tokens in a single loop (list comprehension)\n",
    "    processed_tokens = [\n",
    "        stemmer.stem(word) for word in tokens if word not in stop_words\n",
    "    ]\n",
    "\n",
    "    # Join the processed tokens back into a string (optional)\n",
    "    return \" \".join(processed_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0548a6e4-5fe8-40c8-8aeb-16c4f69a2d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Like to have you 'round  \\r\\nWith all the lies...   \n",
      "1  This Little Light of Mine (Light of Mine),  \\r...   \n",
      "2  She says she's no good with words but I'm wors...   \n",
      "3  Hey mama, mama, come a look at sister,  \\r\\nSh...   \n",
      "4  I see it all through my window it seems.  \\r\\n...   \n",
      "\n",
      "                                      processed_text  \n",
      "0  like round lie make thing dark peopl say tast ...  \n",
      "1  littl light mine light mine im let shine aleil...  \n",
      "2  say she good word im wors bare stutter joke ro...  \n",
      "3  hey mama mama come look sister she astand leve...  \n",
      "4  see window seem never fail like million eel wr...  \n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'processed_text' by applying your function to the 'text' column\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# You can now view the original text side-by-side with the processed text\n",
    "print(df[['text', 'processed_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d69904",
   "metadata": {},
   "source": [
    "### 5. Vectorization: Converting Text to Numbers\n",
    "\n",
    "The next step was to convert the pre-processed lyrical data into a numerical format. I used **TF-IDF (Term Frequency-Inverse Document Frequency)**, a statistical method that reflects how important a word is to a song within the entire dataset.\n",
    "\n",
    "While other methods like Bag-of-Words and Word Embeddings exist, TF-IDF was chosen for this project because it effectively accounts for word importance, which is crucial for a content-based recommendation engine. It provides a strong balance of simplicity and accuracy for our needs.\n",
    "\n",
    "- **`TfidfVectorizer`**: I used scikit-learn's `TfidfVectorizer` to perform this conversion. This tool is highly efficient and handles all the steps—from tokenization to calculating the TF-IDF scores—in a single, optimized operation.\n",
    "- **`tfidf_matrix`**: The result of this process is a sparse matrix, where each row represents a song and each column represents a unique word. The values in the matrix are the TF-IDF scores for each word, which we will use to calculate song similarity.\n",
    "\n",
    "The dimensions of the resulting matrix are (Number of Songs, Number of Unique Words), confirming that our text data has been successfully vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246d08b9-af16-46fd-8002-33bfe64c68c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (5000, 19491)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "# The TfidfVectorizer handles tokenization, counting, and TF-IDF calculation\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the processed text to create the TF-IDF matrix\n",
    "tfidf_matrix = vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "# Print the shape of the matrix to see its dimensions\n",
    "print(\"Shape of TF-IDF matrix:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6812c66a",
   "metadata": {},
   "source": [
    "### 6. Calculating Song Similarity\n",
    "\n",
    "With the lyrical data now in a numerical format, the next step was to measure the similarity between each song. I used **Cosine Similarity**, a metric that calculates the cosine of the angle between two TF-IDF vectors. The resulting score, which ranges from 0 to 1, indicates how similar two songs are in their lyrical content.\n",
    "\n",
    "- **`cosine_similarity()`**: I used scikit-learn's `cosine_similarity` function to compute this metric on our `tfidf_matrix`.\n",
    "- **`cosine_sim`**: The output is a square matrix where each cell represents the similarity score between two songs. For example, `cosine_sim[0][1]` holds the similarity score between the first and second songs in our dataset.\n",
    "\n",
    "This matrix is the core of the recommendation engine, as it provides the foundation for finding and recommending songs similar to a user's selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1550c42",
   "metadata": {},
   "source": [
    "#### (Initial Attempt)\n",
    "\n",
    "An initial attempt to compute the cosine similarity matrix on the full dataset resulted in a MemoryError. The error occurred because the output matrix, which is dense and needs to store a similarity score for every possible pair of songs, was too large to fit in my computer's RAM.\n",
    "\n",
    "The tfidf_matrix, which is a sparse representation of the data, was small enough, but the cosine_similarity() function from scikit-learn attempted to create a dense matrix of shape (57650, 57650) with over 3.3 billion elements, requiring 23.9 GB of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16602668",
   "metadata": {},
   "source": [
    "### 6.1 Solution: Data Sampling (Now move above to just after step 1)\n",
    "To solve this, I chose a common professional strategy: data sampling. By taking a random sample of 5,000 songs from the original dataset, I was able to reduce the size of the TF-IDF matrix, allowing the final cosine similarity matrix to be computed without any memory issues.  This approach allows for the creation of a fully functional and representative proof-of-concept, demonstrating a practical solution to a common data science challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5eb5e6",
   "metadata": {},
   "source": [
    "### 6.2 Calculating Song Similarity (Successful Attempt)\n",
    "After sampling the data, the process was successful. The code below computes the cosine similarity matrix on the now smaller tfidf_matrix. The resulting matrix is the core of our recommendation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fae93ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cosine similarity matrix: (5000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Print the shape of the matrix to see its dimensions\n",
    "print(\"Shape of cosine similarity matrix:\", cosine_sim.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddadb6b",
   "metadata": {},
   "source": [
    "### 7. Building the Recommendation Engine\n",
    "\n",
    "With the cosine similarity matrix computed, the final step was to build the core recommendation function. The `get_recommendations` function takes a song title as input and performs the following tasks:\n",
    "\n",
    "- **Finds the Index**: It uses the song title to locate its corresponding index in the DataFrame.\n",
    "- **Retrieves Scores**: It fetches the similarity scores for that song from the `cosine_sim` matrix.\n",
    "- **Sorts and Filters**: It sorts the scores to find the most similar songs, ensuring the input song itself is not included in the recommendations.\n",
    "- **Returns Recommendations**: It uses the indices of the top-ranked songs to retrieve and display their titles and artists.\n",
    "\n",
    "This final function ties all the previous steps—data cleaning, vectorization, and similarity calculation—together into a complete and functional music recommendation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a921255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_recommendations function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_recommendations(song_title, cosine_sim):\n",
    "    \"\"\"\n",
    "    Generates a list of song recommendations based on lyrical similarity.\n",
    "\n",
    "    The function finds songs with similar lyrical content to a given song\n",
    "    by using a pre-computed cosine similarity matrix.\n",
    "\n",
    "    Args:\n",
    "        song_title (str): The title of the song to get recommendations for.\n",
    "        cosine_sim (np.ndarray): The pre-computed cosine similarity matrix.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of recommended songs, with each song represented as a\n",
    "              Pandas Series containing its information. Returns an empty list\n",
    "              if the song is not found.\n",
    "    \"\"\"\n",
    "    # Find the index of the song that matches the title\n",
    "    # .tolist() is used to convert the Index object to a simple list\n",
    "    song_indices = df.index[df['song'] == song_title].tolist()\n",
    "\n",
    "    # Check if the song was found in the DataFrame\n",
    "    if not song_indices:\n",
    "        print(f\"Song '{song_title}' not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "    # Get the similarity scores for the chosen song from the cosine similarity matrix\n",
    "    # [0] is used to get the single index from the list\n",
    "    sim_scores = cosine_sim[song_indices[0]]\n",
    "\n",
    "    # Get the indices of the songs sorted by similarity score in descending order\n",
    "    # np.argsort returns the indices that would sort the array\n",
    "    # reversed() is used to get them from most to least similar\n",
    "    sorted_indices = np.argsort(sim_scores)\n",
    "    \n",
    "    # Use a list comprehension to filter out the input song's own index\n",
    "    # The list comprehension is a more efficient and \"Pythonic\" way to do this\n",
    "    rec_indices = [\n",
    "        index for index in reversed(sorted_indices)\n",
    "        if index != song_indices[0]\n",
    "    ]\n",
    "\n",
    "    # Take the top 10 recommendations from the filtered list\n",
    "    top_10_rec = rec_indices[:10]\n",
    "\n",
    "    # Use a list comprehension to retrieve the actual songs from the DataFrame\n",
    "    # df.iloc[i] is used to get the entire row (song) by its integer index\n",
    "    recommended_songs = [\n",
    "        df.iloc[i] for i in top_10_rec\n",
    "    ]\n",
    "\n",
    "    return recommended_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9050d6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[artist                                                    New Order\n",
       " song                                                   Transmission\n",
       " link                        /n/new+order/transmission_10191784.html\n",
       " text              Radio, live transmission  \\r\\nRadio, live tran...\n",
       " processed_text    radio live transmiss radio live transmiss list...\n",
       " Name: 4174, dtype: object,\n",
       " artist                                                         Glee\n",
       " song                                            Dancing With Myself\n",
       " link                      /g/glee/dancing+with+myself_20615475.html\n",
       " text              On the floors of Tokyo  \\r\\nDown in London tow...\n",
       " processed_text    floor tokyo london town gogo record select mir...\n",
       " Name: 454, dtype: object,\n",
       " artist                                             Guided By Voices\n",
       " song                                                   Jupiter Spin\n",
       " link                 /g/guided+by+voices/jupiter+spin_21077562.html\n",
       " text              Feel, listen like no one  \\r\\nUses dancing, us...\n",
       " processed_text    feel listen like one use danc use danc mere st...\n",
       " Name: 4694, dtype: object,\n",
       " artist                                                         Kiss\n",
       " song                                       Dance All Over Your Face\n",
       " link                 /k/kiss/dance+all+over+your+face_20079874.html\n",
       " text              Baby, I know it's a jungle out there  \\r\\nWell...\n",
       " processed_text    babi know jungl well play cool play debonair w...\n",
       " Name: 2502, dtype: object,\n",
       " artist                                                      Extreme\n",
       " song                                                Decadence Dance\n",
       " link                       /e/extreme/decadence+dance_20052194.html\n",
       " text              Francis!  \\r\\nFrancis! be careful!  \\r\\n  \\r\\n...\n",
       " processed_text    franci franci care tri hard keep joness run ra...\n",
       " Name: 78, dtype: object,\n",
       " artist                                                 Fall Out Boy\n",
       " song                                                   Dance, Dance\n",
       " link                      /f/fall+out+boy/dance+dance_10113666.html\n",
       " text              She says she's no good with words but I'm wors...\n",
       " processed_text    say she good word im wors bare stutter joke ro...\n",
       " Name: 2, dtype: object,\n",
       " artist                                                          Noa\n",
       " song                                                Again And Again\n",
       " link                           /n/noa/again+and+again_10194390.html\n",
       " text              How many times I say the words  \\r\\nAgain and ...\n",
       " processed_text    mani time say word thousand differ way say lov...\n",
       " Name: 2804, dtype: object,\n",
       " artist                                        Engelbert Humperdinck\n",
       " song                                                  Dance With Me\n",
       " link              /e/engelbert+humperdinck/dance+with+me_2050416...\n",
       " text              Dance with me, I want to be your partner  \\r\\n...\n",
       " processed_text    danc want partner cant see music start night f...\n",
       " Name: 3150, dtype: object,\n",
       " artist                                                 Neil Diamond\n",
       " song                                          Dancing In The Street\n",
       " link              /n/neil+diamond/dancing+in+the+street_20098857...\n",
       " text              (are you ready to let it happen to you tonight...\n",
       " processed_text    readi let happen tonight oh ye man go call rou...\n",
       " Name: 1220, dtype: object,\n",
       " artist                                              Waylon Jennings\n",
       " song                                                      Christina\n",
       " link                     /w/waylon+jennings/christina_20167460.html\n",
       " text              Their eyes were upon me as they sat they're dr...\n",
       " processed_text    eye upon sat theyr drink hand reach lust heart...\n",
       " Name: 1621, dtype: object]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"Halloween Dance\", cosine_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
